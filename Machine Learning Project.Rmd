---
title: "Can Accelerometer Data Identify Exercise Type?"
author: "Chris Walsh"
date: "May 26, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(ggplot2)
require(caret)
require(dplyr)
require(scales)
```

## Synopsis

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. One thing that people regularly do is quantify *how much* of a particular activity they do, but they rarely quantify *how well* they do it. This analysis uses data from accelerometers on the belt, forearm, arm, and dumbell to predict both what kind of lift was taking place and whether it was done correctly.

## Data Load

```{r load.data}
training <- read.csv("pml-training.csv", na.strings = c("NA", ""))
testing <- read.csv("pml-testing.csv", na.strings = c("NA", ""))

training <- training %>% select(-c(1:7))
NAcols <- sapply(training, function(x) sum(is.na(x))/length(x))
training <- training %>% select(-one_of(names(NAcols[NAcols > 0.3])))

nzv <- nearZeroVar(training, saveMetrics=TRUE)
sum(nzv$nzv)
```

Though our primary objective is based around the exercise classification (found in the variable `classe`), the `str` function shows a substantial number of potential predictors. Columns 1-7 can be dropped as they do not appear to offer predictive value. After also dropping a number of columns that are more than 30% missing, we are left with `r length(names(training))-1` potential predictors. A final check is made for columns with near-zero variance. Seeing none, the data is ready for modeling.

```{r partition.data}
set.seed(3826) 
inTrain <- createDataPartition(training$classe, p = 0.7, list = FALSE)
train <- training[inTrain, ]
validate <- training[-inTrain, ]
```

In order to better estimate out-of-sample errors, the training data must also be partitoned. Above, the data was partitioned based on a 70/30 split on the dependent `classe` variable.

## Linear Discriminant Analysis

An initial model can be built using Linear Discriminant Anaylsis. This is a simple linear classifier that can be extended to multi-class problems, though it is limited to linear combinations of features. 5-folds cross validation will be used to avoid overfitting.

```{r train.lda, cache = TRUE, message=FALSE, warning = FALSE}
control <- trainControl(method = "cv", number = 5)
ldaFit <- train(classe ~., data = train, method = "lda", trControl = control)
prediction <- predict(ldaFit, validate)
cm <- confusionMatrix(prediction, validate$classe)
print(cm)
```

This simple LDA model was able to achieve an accuracy of `r percent(round(cm$overall[1],3))` on the out-of-sample validation set.

## Support Vector Machine

LDA also makes some assumptions about the normality of the underlying features. A Support Vector Machine was also fitted to the data in order to relax these assumptions of normality. 

```{r train.svm, cache = TRUE, message=FALSE, warning = FALSE}
svmFit <- train(classe ~., data = train, method = "svmLinear2", trControl = control)
prediction <- predict(svmFit, validate)
cm <- confusionMatrix(prediction, validate$classe)
print(cm)
```

Using the same cross validation, this model was able to achieve an accuracy of `r percent(round(cm$overall[1],3))` on the out-of-sample validation set.

## Random Forest

Finally, as a multi-class problem with a relatively large number of observations, a random forest was fitted.

```{r train.randomforest, cache = TRUE, message=FALSE, warning = FALSE}
rfFit <- train(classe ~., data = train, method = "rf", trControl = control)
prediction <- predict(rfFit, validate)
cm <- confusionMatrix(prediction, validate$classe)
print(cm)
```

Using the same cross validation, this model was able to achieve an accuracy of `r percent(round(cm$overall[1],3))` on the out-of-sample validation set, corresponding to an estimated out-of-sample error of `r percent(1-round(cm$overall[1],3))`. The random forest performs signficantly better than the previous models, suggesting these features do not interact linearly. 

The random forest model took a substantial amount of time to train. To potentially accelerate this process in a production environment, the model could potentially be retrained on the most important predictors as seen in the variable importance plot below and evaluated for accuracy loss.

```{r varimp.randomforest, cache = TRUE, warning = FALSE}
varImpPlot(rfFit$finalModel, cex = .75)
```

## Prediction

The random forest proved to be the most acccurate model by a substantial margin, with an estimated out-of-sample error of `r percent(1-round(cm$overall[1],3))`. Based on this model, the following predictions were made against the final testing set and will be used in the quiz.

```{r predict.randomforest, message = FALSE}
prediction <- predict(rfFit, testing)
print(prediction)
```



